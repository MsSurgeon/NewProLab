{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<img width=\"50px\" align=\"left\" style=\"margin-right:20px\" src=\"http://data.newprolab.com/public-newprolab-com/npl_logo.png\"> <b>New Professions Lab</b> <br /> Специалист по большим данным"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Проект 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Спрогнозировать пол и возрастную категорию интернет-пользователей по логу посещения сайтов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<img width=\"110px\" align=\"left\" src=\"http://data.newprolab.com/public-newprolab-com/project01_img0.png?img\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a href=\"https://github.com/newprolab/content_bigdata6\"><img align=\"left\" src=\"http://data.newprolab.com/public-newprolab-com/npl.svg\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Одна из задач DMP-системы состоит в том, чтобы по разрозненным даннным, таким, как посещения неким пользователем сайтов, классифицировать его и присвоить ему определённую категорию: пол, возраст, интересы и так далее. В дальнейшем составляется портрет, или профиль, пользователя, на основе которого ему более таргетированно показывается реклама в интернете."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Задача"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Используя доступный набор данных о посещении страниц у одной части пользователей, сделать прогноз относительно **пола и возрастной категории** другой части пользователей. Угадывание (hit) - правильное предсказание и пола, и возрастной категории одновременно.\n",
    "\n",
    "Мы не ограничиваем вас в выборе инструментов и методов работы с данными. Используйте любые эвристики, внешние источники, парсинг контента страниц — всё, что поможет вам выполнить задачу. Единственное ограничение — никаких ручных действий. Руками проставлять классы нельзя.\n",
    "\n",
    "Поскольку это ваш проект, который мы наверняка захотите показать другим, уделите его оформлению достаточно времени. Мы рекомендуем сделать весь проект в этом ноутбуке. Снизу, под заданием, вы сможете описать ваше решение.\n",
    "\n",
    "⏰ **Дедлайн: 25 апреля 2017, 23:59**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "from urlparse import urlparse\n",
    "from urllib import urlretrieve, unquote, urlopen\n",
    "import urllib2\n",
    "import cookielib\n",
    "import requests\n",
    "from newspaper import Article\n",
    "import nltk\n",
    "import cPickle as pickle\n",
    "import html2text\n",
    "import xml.etree.cElementTree as ET\n",
    "import bs4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Обработка данных на вход"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Для выполнения работы вам следует взять файл http://data.newprolab.com/data-newprolab-com/project01/gender_age_dataset.txt и положить к себе в директорию `data`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading gender_age_dataset.txt...\n",
      "Download completed\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "# First, we download the input data for the project:\n",
    "\n",
    "data_dir = 'data'\n",
    "filename = 'gender_age_dataset.txt'\n",
    "file_path = '/'.join([data_dir,filename])\n",
    "url = 'http://data.newprolab.com/data-newprolab-com/project01/' + filename\n",
    "\n",
    "if not os.path.isdir(data_dir): os.mkdir(data_dir)\n",
    "if not os.path.isfile(file_path):\n",
    "    print('Downloading ' + filename + '...')\n",
    "    urlretrieve(url, file_path)\n",
    "    print('Download completed')\n",
    "\n",
    "# Wait until you see that all files have been downloaded.\n",
    "print('OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Он содержит данные о посещении сайтов ~40 000 пользователей, при этом по некоторым из них (~ 35 000) известны их пол и возрастная категория, а по 5 000 - эта информация не известна. В файле есть 4 поля:\n",
    "* **gender** - пол, принимающий значения `M` (male - мужчина), `F` (female - женщина), `-` (пол неизвестен);\n",
    "* **age** - возраст, представленный в виде диапазона x-y (строковый тип), или `-` (возрастная категория неизвестна);\n",
    "* **uid** - идентификатор пользователя, строковая переменная;\n",
    "* **user_json** - поле json, в котором содержатся записи о посещении сайтов этим пользователем `(url, timestamp)`.\n",
    "\n",
    "Первое, что обычно делают в таких случаях, — исследуют имеющийся датасет и разбираются, какие же данные мы получили."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Загрузим весь датасет в pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./gender_age_dataset.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender       False\n",
       "age          False\n",
       "uid          False\n",
       "user_json    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isnull(df).sum() > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Как мы можем увидить в данные без пропусков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender\n",
       "-     5000\n",
       "F    17440\n",
       "M    18698\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('gender').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age\n",
       "-         5000\n",
       "18-24     4898\n",
       "25-34    15457\n",
       "35-44     9360\n",
       "45-54     4744\n",
       ">=55      1679\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('age').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>uid</th>\n",
       "      <th>user_json</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>18-24</td>\n",
       "      <td>d50192e5-c44e-4ae8-ae7a-7cfe67c8b777</td>\n",
       "      <td>{\"visits\": [{\"url\": \"http://zebra-zoya.ru/2000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>25-34</td>\n",
       "      <td>d502331d-621e-4721-ada2-5d30b2c3801f</td>\n",
       "      <td>{\"visits\": [{\"url\": \"http://sweetrading.ru/?p=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>25-34</td>\n",
       "      <td>d50237ea-747e-48a2-ba46-d08e71dddfdb</td>\n",
       "      <td>{\"visits\": [{\"url\": \"http://ru.oriflame.com/pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>25-34</td>\n",
       "      <td>d502f29f-d57a-46bf-8703-1cb5f8dcdf03</td>\n",
       "      <td>{\"visits\": [{\"url\": \"http://translate-tattoo.r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>&gt;=55</td>\n",
       "      <td>d503c3b2-a0c2-4f47-bb27-065058c73008</td>\n",
       "      <td>{\"visits\": [{\"url\": \"https://mail.rambler.ru/#...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender    age                                   uid  \\\n",
       "0      F  18-24  d50192e5-c44e-4ae8-ae7a-7cfe67c8b777   \n",
       "1      M  25-34  d502331d-621e-4721-ada2-5d30b2c3801f   \n",
       "2      F  25-34  d50237ea-747e-48a2-ba46-d08e71dddfdb   \n",
       "3      F  25-34  d502f29f-d57a-46bf-8703-1cb5f8dcdf03   \n",
       "4      M   >=55  d503c3b2-a0c2-4f47-bb27-065058c73008   \n",
       "\n",
       "                                           user_json  \n",
       "0  {\"visits\": [{\"url\": \"http://zebra-zoya.ru/2000...  \n",
       "1  {\"visits\": [{\"url\": \"http://sweetrading.ru/?p=...  \n",
       "2  {\"visits\": [{\"url\": \"http://ru.oriflame.com/pr...  \n",
       "3  {\"visits\": [{\"url\": \"http://translate-tattoo.r...  \n",
       "4  {\"visits\": [{\"url\": \"https://mail.rambler.ru/#...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"visits\": [{\"url\": \"http://zebra-zoya.ru/200028-chehol-organayzer-dlja-macbook-11-grid-it.html?utm_campaign=397720794&utm_content=397729344&utm_medium=cpc&utm_source=begun\", \"timestamp\": 1419688144068}, {\"url\": \"http://news.yandex.ru/yandsearch?cl4url=chezasite.com/htc/htc-one-m9-delay-86327.html&lr=213&rpt=story\", \"timestamp\": 1426666298001}, {\"url\": \"http://www.sotovik.ru/news/240283-htc-one-m9-zaderzhivaetsja.html\", \"timestamp\": 1426666298000}, {\"url\": \"http://news.yandex.ru/yandsearch?cl4url=chezasite.com/htc/htc-one-m9-delay-86327.html&lr=213&rpt=story\", \"timestamp\": 1426661722001}, {\"url\": \"http://www.sotovik.ru/news/240283-htc-one-m9-zaderzhivaetsja.html\", \"timestamp\": 1426661722000}]}'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0].user_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1419688144068\n",
      "1426666298001\n",
      "1426666298000\n",
      "1426661722001\n",
      "1426661722000\n"
     ]
    }
   ],
   "source": [
    "jsonv = json.loads('{\"visits\": [{\"url\": \"http://zebra-zoya.ru/200028-chehol-organayzer-dlja-macbook-11-grid-it.html?utm_campaign=397720794&utm_content=397729344&utm_medium=cpc&utm_source=begun\", \"timestamp\": 1419688144068}, {\"url\": \"http://news.yandex.ru/yandsearch?cl4url=chezasite.com/htc/htc-one-m9-delay-86327.html&lr=213&rpt=story\", \"timestamp\": 1426666298001}, {\"url\": \"http://www.sotovik.ru/news/240283-htc-one-m9-zaderzhivaetsja.html\", \"timestamp\": 1426666298000}, {\"url\": \"http://news.yandex.ru/yandsearch?cl4url=chezasite.com/htc/htc-one-m9-delay-86327.html&lr=213&rpt=story\", \"timestamp\": 1426661722001}, {\"url\": \"http://www.sotovik.ru/news/240283-htc-one-m9-zaderzhivaetsja.html\", \"timestamp\": 1426661722000}]}')\n",
    "for visit in jsonv.get('visits'):\n",
    "    print visit['timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5829507\n"
     ]
    }
   ],
   "source": [
    "visit_counter=0 \n",
    "for row in range(df.shape[0]): \n",
    "    visits = json.loads(df.iloc[row].user_json)\n",
    "    visit_counter=visit_counter+len(visits.get('visits'))\n",
    "print visit_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def ParseHTML_v1(article):\n",
    "    text = ''\n",
    "    try:\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        text = article.text\n",
    "    except Exception as e_download::\n",
    "        try:\n",
    "            html = article.html.encode('utf-8')\n",
    "            text = re.sub(r'\\s+', ' ', nltk.clean_html(html))\n",
    "        except Exception as e_nlrk_clean:\n",
    "            pass\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ParseHTML_v2(url):\n",
    "    text = ''\n",
    "    try:\n",
    "        html = urlopen(url).read()\n",
    "        soup = bs4.BeautifulSoup(html)\n",
    "        [s.extract() for s in soup(['style', 'script', '[document]', 'head'])]\n",
    "        text = ' '.join(soup.getText().split())\n",
    "    except:\n",
    "        pass\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_url(url):\n",
    "    try:\n",
    "        a = urlparse(unquote(url.strip()))\n",
    "        if a.netloc == 'news.yandex.ru':\n",
    "                if(re.search('(?<=cl4url=).+(html)', url)):\n",
    "                    url = 'http://' + re.search('(?<=cl4url=).+(html)', url).group(0)\n",
    "                else:\n",
    "                    url = 'http://' + re.search('(?<=cl4url=).+', url).group(0)\n",
    "        stripUrl = str(url).strip()\n",
    "        return stripUrl\n",
    "    except Exception as e_get_url_in:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F\t18-24\td50192e5-c44e-4ae8-ae7a-7cfe67c8b777\t home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} }\n",
      "M\t25-34\td502331d-621e-4721-ada2-5d30b2c3801f\t home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} }  home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } home darknet coq tactics publications projects rĂŠsumĂŠ YOLO: Real-Time Object Detection You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X it processes images at 40-90 FPS and has a mAP on VOC 2007 of 78.6% and a mAP of 44.0% on COCO test-dev. Model Train Test mAP FLOPS FPS Cfg Weights Old YOLO VOC 2007+2012 2007 63.4 40.19 Bn 45 link SSD300 VOC 2007+2012 2007 74.3 - 46 link SSD500 VOC 2007+2012 2007 76.8 - 19 link YOLOv2 VOC 2007+2012 2007 76.8 34.90 Bn 67 cfg weights YOLOv2 544x544 VOC 2007+2012 2007 78.6 59.68 Bn 40 cfg weights Tiny YOLO VOC 2007+2012 2007 57.1 6.97 Bn 207 cfg weights SSD300 COCO trainval test-dev 41.2 - 46 link SSD500 COCO trainval test-dev 46.5 - 19 link YOLOv2 608x608 COCO trainval test-dev 48.1 62.94 Bn 40 cfg weights Tiny YOLO COCO trainval - - 7.07 Bn 200 cfg weights How It Works Prior detection systems repurpose classifiers or localizers to perform detection. They apply the model to an image at multiple locations and scales. High scoring regions of the image are considered detections. We use a totally different approach. We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities. Our model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system. What's New in Version 2? YOLOv2 uses a few tricks to improve training and increase performance. Like Overfeat and SSD we use a fully-convolutional model, but we still train on whole images, not hard negatives. Like Faster R-CNN we adjust priors on bounding boxes instead of predicting the width and height outright. However, we still predict the x and y coordinates directly. The full details are in our paper.! Detection Using A Pre-Trained Model This post will guide you through detecting objects with the YOLO system using a pre-trained model. If you don't already have Darknet installed, you should do that first. Or instead of reading all that just run: git clone https://github.com/pjreddie/darknet cd darknet make Easy! You already have the config file for YOLO in the cfg/ subdirectory. You will have to download the pre-trained weight file here (258 MB). Or just run this: wget http://pjreddie.com/media/files/yolo.weights Then run the detector! ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg You will see some output like this: layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights...Done! data/dog.jpg: Predicted in 0.016287 seconds. car: 54% bicycle: 51% dog: 56% Darknet prints out the objects it detected, its confidence, and how long it took to find them. We didn't compile Darknet with OpenCV so it can't display the detections directly. Instead, it saves them in predictions.png. You can open it to see the detected objects. Since we are using Darknet on the CPU it takes around 6-12 seconds per image. If we use the GPU version it would be much faster. I've included some example images to try in case you need inspiration. Try data/eagle.jpg, data/dog.jpg, data/person.jpg, or data/horses.jpg! The detect command is shorthand for a more general version of the command. It is equivalent to the command: ./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights data/dog.jpg You don't need to know this if all you want to do is run detection on one image but it's useful to know if you want to do other things like run on a webcam (which you will see later on). Multiple Images Instead of supplying an image on the command line, you can leave it blank to try multiple images in a row. Instead you will see a prompt when the config and weights are done loading: ./darknet detect cfg/yolo.cfg yolo.weights layer filters size input output 0 conv 32 3 x 3 / 1 416 x 416 x 3 -> 416 x 416 x 32 1 max 2 x 2 / 2 416 x 416 x 32 -> 208 x 208 x 32 ....... 29 conv 425 1 x 1 / 1 13 x 13 x1024 -> 13 x 13 x 425 30 detection Loading weights from yolo.weights ...Done! Enter Image Path: Enter an image path like data/horses.jpg to have it predict boxes for that image. Once it is done it will prompt you for more paths to try different images. Use Ctrl-C to exit the program once you are done. Changing The Detection Threshold By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command. For example, to display all detection you can set the threshold to 0: ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0 Which produces: So that's obviously not super useful but you can set it to different values to control what gets thresholded by the model. Tiny YOLO Tiny YOLO is based off of the Darknet reference network and is much faster but less accurate than the normal YOLO model. To use the version trained on VOC: wget http://pjreddie.com/media/files/tiny-yolo-voc.weights ./darknet detector test cfg/voc.data cfg/tiny-yolo-voc.cfg tiny-yolo-voc.weights data/dog.jpg Which, ok, it's not perfect, but boy it sure is fast. On GPU it runs at >200 FPS. Real-Time Detection on a Webcam Running YOLO on test data isn't very interesting if you can't see the result. Instead of running it on a bunch of images let's run it on the input from a webcam! To run this demo you will need to compile Darknet with CUDA and OpenCV. Then run the command: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights YOLO will display the current FPS and predicted classes as well as the image with bounding boxes drawn on top of it. You will need a webcam connected to the computer that OpenCV can connect to or it won't work. If you have multiple webcams connected and want to select which one to use you can pass the flag -c <num> to pick (OpenCV uses webcam 0 by default). You can also run it on a video file if OpenCV can read the video: ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file> That's how we made the YouTube video above. Training YOLO on VOC You can train YOLO from scratch if you want to play with different training regimes, hyper-parameters, or datasets. Here's how to get it working on the Pascal VOC dataset. Get The Pascal VOC Data To train YOLO you will need all of the VOC data from 2007 to 2012. You can find links to the data here. To get all the data, make a directory to store it all and from that directory run: curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar tar xf VOCtrainval_11-May-2012.tar tar xf VOCtrainval_06-Nov-2007.tar tar xf VOCtest_06-Nov-2007.tar There will now be a VOCdevkit/ subdirectory with all the VOC training data in it. Generate Labels for VOC Now we need to generate the label files that Darknet uses. Darknet wants a .txt file for each image with a line for each ground truth object in the image that looks like: <object-class> <x> <y> <width> <height> Where x, y, width, and height are relative to the image's width and height. To generate these file we will run the voc_label.py script in Darknet's scripts/ directory. Let's just download it again because we are lazy. curl -O http://pjreddie.com/media/files/voc_label.py python voc_label.py After a few minutes, this script will generate all of the requisite files. Mostly it generates a lot of label files in VOCdevkit/VOC2007/labels/ and VOCdevkit/VOC2012/labels/. In your directory you should see: ls 2007_test.txt VOCdevkit 2007_train.txt voc_label.py 2007_val.txt VOCtest_06-Nov-2007.tar 2012_train.txt VOCtrainval_06-Nov-2007.tar 2012_val.txt VOCtrainval_11-May-2012.tar The text files like 2007_train.txt list the image files for that year and image set. Darknet needs one text file with all of the images you want to train on. In this example, let's train with everything except the 2007 test set so that we can test our model. Run: cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt Now we have all the 2007 trainval and the 2012 trainval set in one big list. That's all we have to do for data setup! Modify Cfg for Pascal Data Now go to your Darknet directory. We have to change the cfg/voc.data config file to point to your data: 1 classes= 20 2 train = <path-to-voc>/train.txt 3 valid = <path-to-voc>2007_test.txt 4 names = data/voc.names 5 backup = backup You should replace <path-to-voc> with the directory where you put the VOC data. Download Pretrained Convolutional Weights For training we use convolutional weights that are pre-trained on Imagenet. We use weights from the Extraction model. You can just download the weights for the convolutional layers here (76 MB). curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 If you want to generate the pre-trained weights yourself, download the pretrained Darknet19 448x448 model and run the following command: ./darknet partial cfg/darknet19_448.cfg darknet19_448.weights darknet19_448.conv.23 23 But if you just download the weights file it's way easier. Train The Model Now we can train! Run the command: ./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 What Happened to the Old YOLO Site? If you are using YOLO version 1 you can still find the site here: http://pjreddie.com/darknet/yolov1/ Cite If you use YOLOv2 in your work please cite our paper! @article{redmon2016yolo9000, title={YOLO9000: Better, Faster, Stronger}, author={Redmon, Joseph and Farhadi, Ali}, journal={arXiv preprint arXiv:1612.08242}, year={2016} } \n"
     ]
    }
   ],
   "source": [
    "user_text = ''\n",
    "\n",
    "for line in list(open('gender_age_dataset_h.txt'))[:2]:\n",
    "    parts = line.strip().split('\\t')\n",
    "    if len(parts) < 4:\n",
    "        continue\n",
    "        \n",
    "    j = json.loads(parts[3])\n",
    "    for visit in j['visits']:\n",
    "        try:\n",
    "            url = get_url(visit['url'].encode('utf-8'))\n",
    "        except Exception as e_get_url:\n",
    "            \n",
    "        ts = visit['timestamp']\n",
    "        try:\n",
    "            article = Article(url, language='ru')\n",
    "            text  = ParseHTML_v1(article)\n",
    "            text = ' '.join(text.split())\n",
    "            user_text = user_text + ' ' + text\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    try:\n",
    "        print (parts[0]+'\\t'+parts[1]+'\\t'+parts[2]+'\\t'+user_text).encode('utf-8').decode('utf-8')        \n",
    "        #print '#######1######'\n",
    "    except:\n",
    "        try:\n",
    "            print (parts[0]+'\\t'+parts[1]+'\\t'+parts[2]+'\\t'+user_text).decode('utf-8')\n",
    "            #print '#######2######'\n",
    "        except:\n",
    "            try:\n",
    "                print (parts[0]+'\\t'+parts[1]+'\\t'+parts[2]+'\\t'+user_text.encode('utf-8'))\n",
    "                #print '#######3######'\n",
    "            except:\n",
    "                try:\n",
    "                    print (parts[0]+'\\t'+parts[1]+'\\t'+parts[2]+'\\t'+user_text.encode('utf-8').decode('utf-8'))\n",
    "                    #print '#######4######'\n",
    "                except:\n",
    "                    print (parts[0]+'\\t'+parts[1]+'\\t'+parts[2]+'\\t'+'None')\n",
    "                    #print '#######5######'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41138/41138 [52:26<00:00, 13.07it/s]  \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "urls = []\n",
    "for row in tqdm(range(df.shape[0])): \n",
    "    visits = json.loads(df.iloc[row].user_json)\n",
    "    for visit in visits.get('visits'):\n",
    "        if str(visit['url'].encode('utf-8')).startswith('http'):\n",
    "            urls.append([df.iloc[row]['uid'],visit['url'].encode('utf-8'), df.iloc[row]['gender']+'_'+df.iloc[row]['age']])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "[url[1] for url in urls[:100]]\n",
    "\n",
    "output = open('urls_h.pkl', 'wb')\n",
    "pickle.dump(urls, output, 2)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "input = open('urls.pkl', 'rb')\n",
    "urls = pickle.load(input)\n",
    "input.close()\n",
    "print urls[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def Pars(url):\n",
    "    parsed_uri = urlparse(url)\n",
    "    netlog = '{uri.netloc}'.format(uri=parsed_uri)\n",
    "    try:\n",
    "        path = '{uri.path}'.format(uri=parsed_uri)\n",
    "    except:\n",
    "        path = url\n",
    "    if netlog == 'news.yandex.ru':\n",
    "        try:\n",
    "            if(re.search('(?<=cl4url=).+(html)', url)):\n",
    "                ya_url = 'http://' + re.search('(?<=cl4url=).+(html)', url).group(0)\n",
    "                article = Article(ya_url, language='ru')\n",
    "            else:\n",
    "                ya_url = 'http://' + re.search('(?<=cl4url=).+', url).group(0)\n",
    "                article = Article(ya_url, language='ru')\n",
    "        except:\n",
    "            article = Article(url, language='ru')\n",
    "    else:\n",
    "        article = Article(url, language='ru')\n",
    "\n",
    "    article.download()\n",
    "    try:\n",
    "        article.parse()\n",
    "    except:\n",
    "        return ''\n",
    "    text = article.text\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    try:    \n",
    "        return (text)\n",
    "    except:\n",
    "        print 'Error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "visits_text = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for url in tqdm(urls[len(visits_text):]):\n",
    "    visits_text.append(Pars(url[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636\n"
     ]
    }
   ],
   "source": [
    "print len(visits_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(visits_list).to_csv('10_userc_visits', encoding='utf-8', )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Методом `pandas.DataFrame.apply` (хотя не только им) можно применить операцию десериализации json-строк ко всему датасету. Рекомендуем почитать [документацию по методу apply](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.apply.html).\n",
    "\n",
    "Работая с подобными операциями, обратите внимание на kwargs-аргумент `axis`. Часто, забыв его указать, вы примените операцию не к ряду (строке), а к столбцу, что вряд ли входит в ваши планы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Очистка данных и feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Очистка данных и генерация новых фич составит значительную часть вашей работы. Именно здесь вы и должны продемонстрировать знания и креативность: чем лучше окажутся ваши фичи и чем лучше сможете убрать шум из датасета, тем лучших результатов вы достигнете."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Одна из первых вещей, которые можно попробовать — это вытащить домены и использовать их в качестве признаков. Можно воспользоваться функцией:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def url2domain(url):\n",
    "    url = re.sub('(http(s)*://)+', 'http://', url)\n",
    "    parsed_url = urlparse(unquote(url.strip()))\n",
    "    if parsed_url.scheme not in ['http','https']: return None\n",
    "    netloc = re.search(\"(?:www\\.)?(.*)\", parsed_url.netloc).group(1)\n",
    "    if netloc is not None: return str(netloc.encode('utf8')).strip()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Поскольку эта часть и есть ваша работа, мы не станем раскрывать все секреты (хотя несколько советов мы всё же дали, посмотрите ниже в разделе Подсказки)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Деление на train и test сеты, обучение модели, предсказания для test-сета"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Давайте теперь оценим размер нашего train и test сетов. Train set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36138"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[~((df.gender == '-') & (df.age == '-'))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[(df.gender == '-') & (df.age == '-')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41138"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df) # Весь датасет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Когда вы очистили данные и сгенерировали признаки, которые можно дать на вход алгоритму, следующий этап — это разделить данные на тренировочную и тестовую выборки. Сохраните train и test выборки в отдельных файлах, используя метод `pandas.DataFrame.to_csv`. Либо просто сделайте два датафрейма: `train_df` и `test_df`. Обучите модель на ваш выбор, оцените результат, подумайте, как можно его улучшить."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Обработка данных на выход\n",
    "Выходной файл должен быть расположен в корне вашей директории в файле `project01_gender-age.csv`. Чекер будет брать файл именно оттуда.\n",
    "\n",
    "Файл должен содержать три поля: `uid` (строковый формат), `gender` (строковый формат) и `age` (строковый формат). \n",
    "\n",
    "В файле должны быть только те пользователи, у которых пол и возрастная категория изначально неизвестны, и они должны быть **отсортированы по UID по возрастанию значений лексикографически.**\n",
    "\n",
    "**Важное замечание!** Вы должны дать прогноз хотя бы по 50% пользователей, у которых изначально не указан пол и возрастная категория. Иными словами, вы можете оставить неопределенными не более 50% изначально неопределенных пользователей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Пример выходного файла:\n",
    "\n",
    "```uid\tgender\tage\n",
    "123\tF\t18-24\n",
    "456\tM\t25-34\n",
    "789\t-\t-\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Файл обязательно должен содержать шапку, указанную выше, и все 5 000 записей по неизвестным пользователям. Итого: 5 001 строка."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Подсказки\n",
    "\n",
    "1. Есть много различных способов решить данную задачу: можно просто хорошо поработать с урлами и доменами, можно пропарсить содержимое этих урлов (заголовки, текст и т.д.) и воспользоваться неким векторизатором типа TF\\*IDF для генерации дополнительных фич, которые уже в дальнейшем вы подадите на вход ML-алгоритму, можно сделать тематическое моделирование (LDA, BigARTM) сайтов и использовать одну или несколько тем в качестве фич.\n",
    "\n",
    "2. Возможно, что данные грязные и их нужно дополнительно обработать. Спецсимволы, кириллические домены? Уделите этому этапу достаточно времени: здесь чистота датасета важнее, чем выбор алгоритма.\n",
    "\n",
    "3. Часто бывает, что лучшее решение с точки зрения результата — оно же самое простое. Попробуйте сначала простые способы, простые алгоритмы, прежде чем переходить к тяжёлой артиллерии. Один из вариантов — начать с небольшого RandomForest.\n",
    "\n",
    "4. Вам почти наверняка понадобится что-то из пакета sklearn. [Документация](http://scikit-learn.org/stable/user_guide.html) — ваш лучший друг.\n",
    "\n",
    "5. Вы можете сначала предсказать пол, а затем возраст, либо сразу и то, и другое. Экспериментируйте.\n",
    "\n",
    "6. В Python 2.7 возможны проблемы с юникодом. Способы решения существуют — обращайтесь в slack за советами.\n",
    "\n",
    "7. Объединяйтесь в команды. Так гораздо веселее и интереснее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Проверка\n",
    "Проверка осуществляется из [Личного кабинета](http://lk.newprolab.com/lab/project01). По файлу будет определяться доля правильно спрогнозированных пользователей (у которых правильно указаны и пол, и возрастная категория).\n",
    "\n",
    "* В поле `part of users with predicted gender + age` - указана доля пользователей, которая была предсказана от общего числа неизвестных пользователей (пример: по 3 000 был сделан прогноз, а всего было неизвестно 5 000, чекер выдаст 0.6).\n",
    "\n",
    "* В поле `correctly predicted users / total number of users` - указана доля пользователей, которая была правильно предсказана (совпадает и пол, и возраст) от общего числа всех пользователей (пример: по 3 000 был сделан прогноз, правильно было спрогнозировано 1 500, а всего было неизвестно 5 000, чекер выдаст 0.3)\n",
    "\n",
    "* В поле `correctly predicted users / number of predicted users` - указана доля пользователей, которая была правильно предсказана (совпадает и пол, и возраст) от общего числа предсказанных пользователей (пример: по 3 000 был сделан прогноз, из них правильно предсказано 1 500, чекер выдаст 0.5).\n",
    "\n",
    "**Если доля в последнем поле превысит порог 0.28, то проект будет засчитан.**\n",
    "\n",
    "Лучшей команде, набравшей максимальный результат, мы подарим специальный приз, о котором скажем позднее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Ваше решение здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
