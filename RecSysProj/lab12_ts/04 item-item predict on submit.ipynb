{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 2.0.2\n",
      "      /_/\n",
      "\n",
      "Using Python version 2.7.6 (default, Mar 22 2014 22:59:56)\n",
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    import os\n",
    "    os.environ[\"PYSPARK_SUBMIT_ARGS\"]='--packages com.databricks:spark-csv_2.10:1.3.0 pyspark-shell'\n",
    "    execfile(os.path.join(os.environ[\"SPARK_HOME\"], 'python/pyspark/shell.py'))\n",
    "    import os\n",
    "    import sys\n",
    "else:\n",
    "    os.environ['SPARK_HOME'] = '/usr/lib/spark'\n",
    "    sys.path.insert(0, '/usr/lib/spark/python/lib/py4j-0.9-src.zip')\n",
    "    sys.path.insert(0, '/usr/lib/spark/python/')\n",
    "    sys.path.insert(0, '/usr/local/lib64/python2.7/site-packages')\n",
    "    sys.path.insert(0,'/usr/local/lib/python2.7/site-packages')\n",
    "    \n",
    "    from pyspark import SparkContext\n",
    "    from pyspark.sql import SQLContext, HiveContext\n",
    "    \n",
    "    try: sc = SparkContext()\n",
    "    except: None    \n",
    "    sqlc = SQLContext(sc)\n",
    "    spark = sqlc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/matplotlib/__init__.py:872: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType, MapType\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from operator import add\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.recommendation import Rating\n",
    "from pyspark.mllib.recommendation import ALS, MatrixFactorizationModel\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "strain_predictions = spark.read.parquet(\"lab_12/cache/full_train_bp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+\n",
      "|userId|movieId|rating|\n",
      "+------+-------+------+\n",
      "| 20833|     31|   4.5|\n",
      "|201833|     31|   3.5|\n",
      "+------+-------+------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "strain_predictions = strain_predictions.select(\"userId\", \"movieId\", \"rating\")\n",
    "strain_predictions.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stest_predictions = spark.read.parquet(\"lab_12/cache/full_test_bp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+--------------+--------------+-------------------+\n",
      "|userId|movieId|n_user_ratings|n_item_ratings|bp_predicted_rating|\n",
      "+------+-------+--------------+--------------+-------------------+\n",
      "|223036|     31|          1376|           161|  3.548151868862599|\n",
      "|  1051|     31|          1108|           161| 2.1218463332398656|\n",
      "+------+-------+--------------+--------------+-------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stest_predictions.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "strain_predictions.registerTempTable(\"strain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stest_predictions.registerTempTable(\"stest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Load similarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_i2i_tupple(line):\n",
    "    r = line.split(',')\n",
    "    return (int(r[0]), int(r[1]), float(r[2]), int(r[3]))\n",
    "\n",
    "def load_i2i_sim():\n",
    "    raw = sc.textFile(\"lab_12/i2itop100.csv\")\\\n",
    "            .filter(lambda x: not x.startswith(\"item\"))\\\n",
    "            .map(convert_i2i_tupple)\n",
    "    return raw.toDF(schema=StructType([StructField(\"item1\",  IntegerType()),\n",
    "                                       StructField(\"item2\", IntegerType()),\n",
    "                                       StructField(\"sim\",  FloatType()),\n",
    "                                       StructField(\"sim_rank\",  IntegerType())])) \n",
    "    return raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i2i = load_i2i_sim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+----------+--------+\n",
      "|item1|item2|       sim|sim_rank|\n",
      "+-----+-----+----------+--------+\n",
      "|    4| 7815| 0.8488138|       0|\n",
      "|    4|24898|0.83807796|       1|\n",
      "+-----+-----+----------+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i2i.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i2i.registerTempTable(\"i2i_sim\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q = spark.sql(\"\"\"\n",
    "        select\n",
    "          pr.userId,\n",
    "          pr.movieId,\n",
    "          sum(kr.rating * s.sim) /  sum(s.sim) as predicted_rating,\n",
    "          count(*) as n_used_ratings\n",
    "        from stest pr\n",
    "        join i2i_sim s on pr.movieId = s.item1 and s.sim_rank <= 100\n",
    "        join strain kr on pr.userId = kr.userId and kr.movieId = s.item2\n",
    "        group by pr.userId, pr.movieId\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+-----------------+--------------+\n",
      "|userId|movieId| predicted_rating|n_used_ratings|\n",
      "+------+-------+-----------------+--------------+\n",
      "|   586|  10665|2.748026606639374|             8|\n",
      "|  1065|  21942|4.353618564178993|            10|\n",
      "+------+-------+-----------------+--------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_on_test = q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_on_test.registerTempTable(\"predicted_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eval_data = spark.sql(\"\"\"\n",
    "        select\n",
    "          tbase.*,\n",
    "          coalesce(pt.n_used_ratings, 0) as n_used_item_ratings,\n",
    "          coalesce(predicted_rating, bp_predicted_rating) as predicted_i2i_rating,\n",
    "          if(pt.n_used_ratings is not null, 1, 0) as has_i2i_rating\n",
    "        from stest tbase\n",
    "        left join predicted_test  pt on tbase.userId = pt.userId and tbase.movieId = pt.movieId\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[userId: int, movieId: int, n_user_ratings: bigint, n_item_ratings: bigint, bp_predicted_rating: double, n_used_item_ratings: bigint, predicted_i2i_rating: double, has_i2i_rating: int]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_data.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+--------------+--------------+-------------------+-------------------+--------------------+--------------+\n",
      "|userId|movieId|n_user_ratings|n_item_ratings|bp_predicted_rating|n_used_item_ratings|predicted_i2i_rating|has_i2i_rating|\n",
      "+------+-------+--------------+--------------+-------------------+-------------------+--------------------+--------------+\n",
      "|    28|   2111|           335|            37| 3.1485874853613227|                  4|  3.2485096794471175|             1|\n",
      "|    30|  22037|            28|         32123| 3.1463153925797798|                  3|    4.66988878407485|             1|\n",
      "+------+-------+--------------+--------------+-------------------+-------------------+--------------------+--------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_data.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save for ensemble cheks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eval_data = eval_data.coalesce(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#eval_data.write.parquet(\"lab_12/cache/full_test_bp_i2i_top100\", mode='overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Export as csv for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res_pd = eval_data.select(\"userId\", \"movieId\", \"bp_predicted_rating\", \"predicted_i2i_rating\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#res_pd.to_csv(\"/data/home/taras.svirsky/lab12/res/full_test_bp_i2i_top100.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10531564, 4)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_pd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
