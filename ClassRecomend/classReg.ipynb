{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 2.1.1\n",
      "      /_/\n",
      "\n",
      "Using Python version 2.7.6 (default, Oct 26 2016 20:30:19)\n",
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"]='--packages com.databricks:spark-csv_2.10:1.2.0 pyspark-shell'\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "sys.path.insert(0, spark_home + \"/python\")\n",
    "execfile(os.path.join(spark_home, 'python/pyspark/shell.py'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"/labs/lab07data/DO_record_per_line.json\"\n",
    "cl= spark.read.json(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cat: string (nullable = true)\n",
      " |-- desc: string (nullable = true)\n",
      " |-- id: long (nullable = true)\n",
      " |-- lang: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- provider: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cl.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(cat=u'3/business_management|6/economics_finance', desc=u'This course introduces the basic financial statements used by most businesses, as well as the essential tools used to prepare them. This course will serve as a resource to help business students succeed in their upcoming university-level accounting classes, and as a refresher for upper division accounting students who are struggling to recall elementary concepts essential to more advanced accounting topics. Business owners will also benefit from this class by gaining essential skills necessary to organize and manage information pertinent to operating their business. At the conclusion of the class, students will understand the balance sheet, income statement, and cash flow statement. They will be able to differentiate between cash basis and accrual basis techniques, and know when each is appropriate. They\\u2019ll also understand the accounting equation, how to journalize and post transactions, how to adjust and close accounts, and how to prepare key financial reports. All material for this class is written and delivered by the professor, and can be previewed here. Students must have access to a spreadsheet program to participate.', id=4, lang=u'en', name=u'Accounting Cycle: The Foundation of Business Measurement and Reporting', provider=u'Canvas Network')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "targets = [26014, 14205, 12290, 17953, 12201, 21022]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(lang=u'ru', id=12201),\n",
       " Row(lang=u'es', id=12290),\n",
       " Row(lang=u'en', id=14205),\n",
       " Row(lang=u'es', id=17953),\n",
       " Row(lang=u'ru', id=21022),\n",
       " Row(lang=u'en', id=26014)]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl[cl['id'].isin(targets)].select('lang', 'id').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The best way to prepare for CCIE Routing and Switching Version 5 certification. \n",
      "#############################################################\n",
      "Highlights the important new features of the latest release of ColdFusion, a dynamic web application builder.\n",
      "#############################################################\n",
      "\n",
      "En este curso aprenderemos a modelar con 3Ds Max cuatro objetos imprescindibles para escenas de interiores, tales como sillas, cojines, sofas y mesas.\n",
      "3dsMax es un programa de creación de gráficos y animación 3D desarrollado por Autodesk, en concreto la división Autodesk Media &amp; Entertainment (anteriormente Discreet). Creado inicialmente por el Grupo Yost para Autodesk, salió a la venta por primera vez en 1990 para DOS. 3ds Max, con su arquitectura basada en plugins, es uno de los programas de animación 3D más utilizado, especialmente para la creación de video juegos, anuncios de televisión, en arquitectura o en películas. Este curso es impartido por Juani Utrillas, generalista 3D. Lleva mas de 10 años trabajando con el programa 3d studio max, sobre todo en el campo de la infoarquitectura para empresas de construcción realizando renders arquitectonicos con Vray y Mental Ray. También maneja más funciones de 3Ds max como es la animación y el modelado . Category:\n",
      "Technology \n",
      "#############################################################\n",
      " 4 pistas de entrenamiento. Aprende las técnicas necesarias en el agility de hoy. Incluidas las correcciones individuales O/E agility training courses se desarrolla para usted en la búsqueda de nuevos retos en su camino de alcanzar un nivel más alto de agility. Este pack incluye 4 pistas de entrenamientos con videos ilustrativos de diferentes recorridos para realizar la pista. Diferentes trayectorias son analizadas con el fin de encontrar el recorrido más rápido para usted y su perro. Este pack incluye la posibilidad para usted de grabar sus ejercicios y enviárnoslos vía dropbox para recibir consejos y correcciones sobre sus videos. Cada una de las cuatro pistas empieza con el diseño de la pista y el reconocimiento de cada una. Después de esto, veremos las diferentes opciones de guiado en nuestra búsqueda del recorrido más rápido. Veremos las distintas técnicas de movimientos y cómo enseñarselas a vuestro perro. Por lo tanto, independientemente de que estéis compitiendo a un alto nivel y busquéis un entrenador que acabéis de empezar y estéis buscando consejos para poder mejorar, este curso no os lo podéis perder. What are the requirements? Con el fin de conseguir el máximo beneficio de los cursos online OE necesitaréis tener una pista de agility con obstáculos normales de entrenamiento. También necesitaréis una cámara o un smart phone para grabar vuestros ejercicios. What am I going to get from this course? Over 6 lectures and 34 mins of content! El objetivo es hacer un agility de gran calidad apto para cualquier persona. En este curso aprenderéis las técnicas más importantes, cómo entrenarlas tanto para vosotros como para vuestro perro y cómo mantenerlas y seguir desarrollandolas aún más. What is the target audience? El curso está diseñado para perros que ya están compitiendo pero para perros jóvenes y sus dueños encontrarán mucha información válida para desarrollar las técnicas y conseguir un alto nivel en competición. SECTION 1: Para empezar\n",
      "Para empezarSECTION 2: Pistas de entrenamiento\n",
      "Pista 1Pista 2Pista 3Pista 4SECTION 3: Material Extra\n",
      "El Ketschker\n",
      "#############################################################\n",
      "Курс ориентирован на людей, имеющих небольшой опыт программирования на современных языках и желающих научиться основам программирования для операционной системы Android.\n",
      "#############################################################\n",
      "Этот курс разработан для маленьких слушателей, изучающих русский язык как неродной. Он поможет им узнать больше как о самом русском языке, так и о России, стране его распространения. Мы познакомим ребят с основными элементами языка и расскажем о великих русских писателях и поэтах, поговорим о числах и геометрических фигурах и обсудим природу России. А поможет нам в этом маленький любознательный лисенок! Цель курса – расширение кругозора у детей младшего школьного возраста посредством освоения содержания российского начального образования и приобщения к русской культуре. Задачи курса – совершенствование навыков русского языка у  детей, проживающих за рубежом и иностранных детей, изучающих русский язык; развитие интереса к России и ее образовательным ресурсам. Лекции и задания курса предполагают как самостоятельную работу детей, так и работу совместно с родителями.\n",
      "#############################################################\n"
     ]
    }
   ],
   "source": [
    "for tr in targets:\n",
    "    print cl[cl['id']==tr].take(1)[0][1]\n",
    "    print ('#############################################################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.feature import HashingTF\n",
    "from pyspark.mllib.feature import IDF\n",
    "\n",
    "from pyspark.mllib.feature import Normalizer\n",
    "normalizer_l2 = Normalizer(p=2)\n",
    "\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf = HashingTF(10000)\n",
    "idf = IDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regex = re.compile(ur'[\\w\\d]{2,}', re.U)\n",
    "\n",
    "def tokens(x):\n",
    "    tokens = regex.findall(x.lower())\n",
    "    return tokens    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_cosine_similarity(a,b):\n",
    "    return a.dot(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cl_ru = cl[cl['lang']=='ru']\n",
    "cl_ru_rdd = cl[cl['lang']=='ru'].rdd\n",
    "ru_12201 = cl_ru[cl_ru['id']==12201].rdd\n",
    "ru_21022 = cl_ru[cl_ru['id']==21022].rdd\n",
    "\n",
    "bag_ru = cl_ru_rdd.map(lambda x: x[1]).map(tokens)\n",
    "\n",
    "bag_12201 = ru_12201.map(lambda x: x[1]).map(tokens)\n",
    "bag_21022 = ru_21022.map(lambda x: x[1]).map(tokens)\n",
    "\n",
    "tfs_ru = tf.transform(bag_ru)\n",
    "tfs_12201 = tf.transform(bag_12201)\n",
    "tfs_21022 = tf.transform(bag_21022)\n",
    "\n",
    "idf_ru_model = idf.fit(tfs_ru)\n",
    "tf_idf_ru = idf_ru_model.transform(tfs_ru)\n",
    "\n",
    "tf_idf_12201 = idf_ru_model.transform(tfs_12201)\n",
    "tf_idf_21022 = idf_ru_model.transform(tfs_21022)\n",
    "\n",
    "norm_tf_idf_ru = normalizer_l2.transform(tf_idf_ru)\n",
    "\n",
    "norm_tf_idf_12201 = normalizer_l2.transform(tf_idf_12201)\n",
    "norm_tf_idf_21022 = normalizer_l2.transform(tf_idf_21022)\n",
    "\n",
    "tr_12201 = norm_tf_idf_12201.take(1)[0]\n",
    "tr_21022 = norm_tf_idf_21022.take(1)[0]\n",
    "\n",
    "similarities_12201 = norm_tf_idf_ru.map(lambda x: calc_cosine_similarity(x, tr_12201))\n",
    "similarities_21022 = norm_tf_idf_ru.map(lambda x: calc_cosine_similarity(x, tr_21022))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ru_index_list_12201 = []\n",
    "ru_list_12201 = []\n",
    "for e in list(similarities_12201.zipWithIndex().takeOrdered(11, lambda x: -x[0])):\n",
    "    ru_index_list_12201.append(e[1])\n",
    "ru_index_list_12201.pop(0)\n",
    "for i in ru_index_list_12201:\n",
    "    ru_list_12201.append(cl_ru_rdd.zipWithIndex().filter(lambda (value,index) : index == i). \\\n",
    "        map(lambda (value,index): value).take(1)[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ru_index_list_21022 = []\n",
    "ru_list_21022 = []\n",
    "for e in list(similarities_21022.zipWithIndex().takeOrdered(11, lambda x: -x[0])):\n",
    "    ru_index_list_21022.append(e[1])\n",
    "ru_index_list_21022.pop(0)\n",
    "for i in ru_index_list_21022:\n",
    "    ru_list_21022.append(cl_ru_rdd.zipWithIndex().filter(lambda (value,index) : index == i). \\\n",
    "        map(lambda (value,index): value).take(1)[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cl_en = cl[cl['lang']=='en']\n",
    "cl_en_rdd = cl[cl['lang']=='en'].rdd\n",
    "en_14205 = cl_en[cl_en['id']==14205].rdd\n",
    "en_26014 = cl_en[cl_en['id']==26014].rdd\n",
    "\n",
    "bag_en = cl_en_rdd.map(lambda x: x[1]).map(tokens)\n",
    "\n",
    "bag_14205 = en_14205.map(lambda x: x[1]).map(tokens)\n",
    "bag_26014 = en_26014.map(lambda x: x[1]).map(tokens)\n",
    "\n",
    "tfs_en = tf.transform(bag_en)\n",
    "tfs_14205 = tf.transform(bag_14205)\n",
    "tfs_26014 = tf.transform(bag_26014)\n",
    "\n",
    "idf_en_model = idf.fit(tfs_en)\n",
    "tf_idf_en = idf_en_model.transform(tfs_en)\n",
    "\n",
    "tf_idf_14205 = idf_en_model.transform(tfs_14205)\n",
    "tf_idf_26014 = idf_en_model.transform(tfs_26014)\n",
    "\n",
    "norm_tf_idf_en = normalizer_l2.transform(tf_idf_en)\n",
    "\n",
    "norm_tf_idf_14205 = normalizer_l2.transform(tf_idf_14205)\n",
    "norm_tf_idf_26014 = normalizer_l2.transform(tf_idf_26014)\n",
    "\n",
    "tr_14205 = norm_tf_idf_14205.take(1)[0]\n",
    "tr_26014 = norm_tf_idf_26014.take(1)[0]\n",
    "\n",
    "similarities_14205 = norm_tf_idf_en.map(lambda x: calc_cosine_similarity(x, tr_14205))\n",
    "similarities_26014 = norm_tf_idf_en.map(lambda x: calc_cosine_similarity(x, tr_26014))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "en_index_list_14205 = []\n",
    "en_list_14205 = []\n",
    "for e in list(similarities_14205.zipWithIndex().takeOrdered(11, lambda x: -x[0])):\n",
    "    en_index_list_14205.append(e[1])\n",
    "en_index_list_14205.pop(0)\n",
    "for i in en_index_list_14205:\n",
    "    en_list_14205.append(cl_en_rdd.zipWithIndex().filter(lambda (value,index) : index == i). \\\n",
    "        map(lambda (value,index): value).take(1)[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "en_index_list_26014 = []\n",
    "en_list_26014 = []\n",
    "for e in list(similarities_26014.zipWithIndex().takeOrdered(11, lambda x: -x[0])):\n",
    "    en_index_list_26014.append(e[1])\n",
    "en_index_list_26014.pop(0)\n",
    "for i in en_index_list_26014:\n",
    "    en_list_26014.append(cl_en_rdd.zipWithIndex().filter(lambda (value,index) : index == i). \\\n",
    "        map(lambda (value,index): value).take(1)[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cl_es = cl[cl['lang']=='es']\n",
    "cl_es_rdd = cl[cl['lang']=='es'].rdd\n",
    "es_12290 = cl_es[cl_es['id']==12290].rdd\n",
    "es_17953 = cl_es[cl_es['id']==17953].rdd\n",
    "\n",
    "bag_es = cl_es_rdd.map(lambda x: x[1]).map(tokens)\n",
    "\n",
    "bag_12290 = es_12290.map(lambda x: x[1]).map(tokens)\n",
    "bag_17953 = es_17953.map(lambda x: x[1]).map(tokens)\n",
    "\n",
    "tfs_es = tf.transform(bag_es)\n",
    "tfs_12290 = tf.transform(bag_12290)\n",
    "tfs_17953 = tf.transform(bag_17953)\n",
    "\n",
    "idf_es_model = idf.fit(tfs_es)\n",
    "tf_idf_es = idf_es_model.transform(tfs_es)\n",
    "\n",
    "tf_idf_12290 = idf_es_model.transform(tfs_12290)\n",
    "tf_idf_17953 = idf_es_model.transform(tfs_17953)\n",
    "\n",
    "norm_tf_idf_es = normalizer_l2.transform(tf_idf_es)\n",
    "\n",
    "norm_tf_idf_12290 = normalizer_l2.transform(tf_idf_12290)\n",
    "norm_tf_idf_17953 = normalizer_l2.transform(tf_idf_17953)\n",
    "\n",
    "tr_12290 = norm_tf_idf_12290.take(1)[0]\n",
    "tr_17953 = norm_tf_idf_17953.take(1)[0]\n",
    "\n",
    "similarities_12290 = norm_tf_idf_es.map(lambda x: calc_cosine_similarity(x, tr_12290))\n",
    "similarities_17953 = norm_tf_idf_es.map(lambda x: calc_cosine_similarity(x, tr_17953))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "es_index_list_12290 = []\n",
    "es_list_12290 = []\n",
    "for e in list(similarities_12290.zipWithIndex().takeOrdered(11, lambda x: -x[0])):\n",
    "    es_index_list_12290.append(e[1])\n",
    "es_index_list_12290.pop(0)\n",
    "for i in es_index_list_12290:\n",
    "    es_list_12290.append(cl_es_rdd.zipWithIndex().filter(lambda (value,index) : index == i). \\\n",
    "        map(lambda (value,index): value).take(1)[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "es_index_list_17953 = []\n",
    "es_list_17953 = []\n",
    "for e in list(similarities_17953.zipWithIndex().takeOrdered(11, lambda x: -x[0])):\n",
    "    es_index_list_17953.append(e[1])\n",
    "es_index_list_17953.pop(0)\n",
    "for i in es_index_list_17953:\n",
    "    es_list_17953.append(cl_es_rdd.zipWithIndex().filter(lambda (value,index) : index == i). \\\n",
    "        map(lambda (value,index): value).take(1)[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = cl.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cos_m(x, y):\n",
    "    return abs(cosine_similarity(x, y)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_es = pd.DataFrame()\n",
    "df_es = df[df['lang'] == 'es']\n",
    "df_es.reset_index(inplace = True, drop = True)\n",
    "\n",
    "es_desc = list(df_es['desc'])\n",
    "tf_v_es = TfidfVectorizer(norm=None, smooth_idf=False)\n",
    "matrix_es = tf_v_es.fit_transform(es_desc).toarray()\n",
    "\n",
    "cos_17953 = []\n",
    "\n",
    "for i in range(matrix_es.shape[0]):\n",
    "    \n",
    "    cos_17953.append(cos_m(matrix_es[df_es[df_es['id'] == 17953].index[0]], matrix_es[i]))\n",
    "\n",
    "df_es['cos_17953'] = cos_17953\n",
    "\n",
    "\n",
    "df_es.sort_values(by = ['cos_17953', 'name', 'id'], ascending=[False, True, True], inplace = True)\n",
    "top10_17953 = list(df_es['id'].iloc[1:11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"../lab07.json\", \"w\") as outfile:\n",
    "    json.dump({'12290':es_list_12290, '17953':top10_17953, '14205':en_list_14205, '26014':en_list_26014,\n",
    "            '12201':ru_list_12201, '21022':ru_list_21022 }, outfile, indent=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"../lab07s.json\", \"w\") as outfile:\n",
    "    json.dump({'12290':es_list_12290, '17953':top10_17953, '14205':en_list_14205, '26014':en_list_26014,\n",
    "            '12201':ru_list_12201, '21022':ru_list_21022 }, outfile, indent=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
